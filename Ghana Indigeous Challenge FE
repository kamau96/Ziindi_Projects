{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12806871,"sourceType":"datasetVersion","datasetId":8097839}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext cudf.pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T17:51:28.521366Z","iopub.execute_input":"2025-09-19T17:51:28.521597Z","iopub.status.idle":"2025-09-19T17:51:36.179473Z","shell.execute_reply.started":"2025-09-19T17:51:28.521572Z","shell.execute_reply":"2025-09-19T17:51:36.178844Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import numpy as np, pandas as pd, itertools\npd.set_option('display.max_columns', 500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T17:51:36.180817Z","iopub.execute_input":"2025-09-19T17:51:36.181249Z","iopub.status.idle":"2025-09-19T17:51:36.274613Z","shell.execute_reply.started":"2025-09-19T17:51:36.181228Z","shell.execute_reply":"2025-09-19T17:51:36.273841Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_path = \"/kaggle/input/indigenous-knowledge/train (1).csv\"\ntest_path = \"/kaggle/input/indigenous-knowledge/test.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T17:51:36.275466Z","iopub.execute_input":"2025-09-19T17:51:36.275715Z","iopub.status.idle":"2025-09-19T17:51:36.279196Z","shell.execute_reply.started":"2025-09-19T17:51:36.275693Z","shell.execute_reply":"2025-09-19T17:51:36.278523Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train = pd.read_csv(train_path)\ntrain[\"prediction_time\"] = pd.to_datetime( train[\"prediction_time\"] )\ntrain[\"month\"] = train[\"prediction_time\"].dt.month.astype(\"float32\")\ntrain[\"day\"] = train[\"prediction_time\"].dt.day.astype(\"float32\")\ntrain[\"dow\"] = train[\"prediction_time\"].dt.dayofweek.astype(\"float32\")\nprint( train.shape )\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T17:51:36.280011Z","iopub.execute_input":"2025-09-19T17:51:36.280253Z","iopub.status.idle":"2025-09-19T17:51:36.926336Z","shell.execute_reply.started":"2025-09-19T17:51:36.280228Z","shell.execute_reply":"2025-09-19T17:51:36.925387Z"}},"outputs":[{"name":"stdout","text":"(10928, 15)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"            ID  user_id  confidence  predicted_intensity community  \\\n0  ID_KwcTp_12       11         0.3                  0.0    Tumfa    \n1  ID_K9vWT_12       17         0.3                  0.0  Kwabeng    \n2  ID_AIQg3_12       19         0.3                  0.0  Akropong   \n3  ID_px4yf_12       23         0.3                  0.0   Asamama   \n4  ID_QYYmK_12       23         0.3                  0.0   Asamama   \n\n     district     prediction_time indicator indicator_description  \\\n0  atiwa_west 2025-05-30 11:09:33      <NA>                  <NA>   \n1  atiwa_west 2025-05-30 11:09:35      <NA>                  <NA>   \n2  atiwa_west 2025-05-30 11:09:47      <NA>                  <NA>   \n3  atiwa_west 2025-05-30 11:16:33      <NA>                  <NA>   \n4  atiwa_west 2025-05-30 11:16:55      <NA>                  <NA>   \n\n  time_observed      Target  forecast_length  month   day  dow  \n0          <NA>  MEDIUMRAIN               12    5.0  30.0  4.0  \n1          <NA>   HEAVYRAIN               12    5.0  30.0  4.0  \n2          <NA>  MEDIUMRAIN               12    5.0  30.0  4.0  \n3          <NA>   HEAVYRAIN               12    5.0  30.0  4.0  \n4          <NA>   HEAVYRAIN               12    5.0  30.0  4.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>user_id</th>\n      <th>confidence</th>\n      <th>predicted_intensity</th>\n      <th>community</th>\n      <th>district</th>\n      <th>prediction_time</th>\n      <th>indicator</th>\n      <th>indicator_description</th>\n      <th>time_observed</th>\n      <th>Target</th>\n      <th>forecast_length</th>\n      <th>month</th>\n      <th>day</th>\n      <th>dow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_KwcTp_12</td>\n      <td>11</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>Tumfa</td>\n      <td>atiwa_west</td>\n      <td>2025-05-30 11:09:33</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>MEDIUMRAIN</td>\n      <td>12</td>\n      <td>5.0</td>\n      <td>30.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_K9vWT_12</td>\n      <td>17</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>Kwabeng</td>\n      <td>atiwa_west</td>\n      <td>2025-05-30 11:09:35</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>HEAVYRAIN</td>\n      <td>12</td>\n      <td>5.0</td>\n      <td>30.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_AIQg3_12</td>\n      <td>19</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>Akropong</td>\n      <td>atiwa_west</td>\n      <td>2025-05-30 11:09:47</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>MEDIUMRAIN</td>\n      <td>12</td>\n      <td>5.0</td>\n      <td>30.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_px4yf_12</td>\n      <td>23</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>Asamama</td>\n      <td>atiwa_west</td>\n      <td>2025-05-30 11:16:33</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>HEAVYRAIN</td>\n      <td>12</td>\n      <td>5.0</td>\n      <td>30.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_QYYmK_12</td>\n      <td>23</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>Asamama</td>\n      <td>atiwa_west</td>\n      <td>2025-05-30 11:16:55</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>HEAVYRAIN</td>\n      <td>12</td>\n      <td>5.0</td>\n      <td>30.0</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"test = pd.read_csv(test_path)\ntest[\"prediction_time\"] = pd.to_datetime( test[\"prediction_time\"] )\ntest[\"month\"] = test[\"prediction_time\"].dt.month.astype(\"float32\")\ntest[\"day\"] = test[\"prediction_time\"].dt.day.astype(\"float32\")\ntest[\"dow\"] = test[\"prediction_time\"].dt.dayofweek.astype(\"float32\")\nprint( test.shape )\ntest.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T17:51:36.927577Z","iopub.execute_input":"2025-09-19T17:51:36.928158Z","iopub.status.idle":"2025-09-19T17:51:36.990738Z","shell.execute_reply.started":"2025-09-19T17:51:36.928128Z","shell.execute_reply":"2025-09-19T17:51:36.990023Z"}},"outputs":[{"name":"stdout","text":"(2732, 14)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"            ID  user_id  confidence  predicted_intensity         community  \\\n0  ID_SbTdy_24       77         0.3                  0.0  ASSIN BROFOYEDUR   \n1  ID_SBKYz_24       77         0.3                  0.0  ASSIN BROFOYEDUR   \n2  ID_fAimg_24       77         0.3                  0.0  ASSIN BROFOYEDUR   \n3  ID_2wBqC_24       77         0.3                  0.0  ASSIN BROFOYEDUR   \n4  ID_NItox_24       77         0.3                  0.0  ASSIN BROFOYEDUR   \n\n     district     prediction_time indicator indicator_description  \\\n0  assin_fosu 2025-07-20 19:27:28      <NA>                  <NA>   \n1  assin_fosu 2025-07-20 19:27:29      <NA>                  <NA>   \n2  assin_fosu 2025-07-20 19:27:30      <NA>                  <NA>   \n3  assin_fosu 2025-07-20 19:27:31      <NA>                  <NA>   \n4  assin_fosu 2025-07-20 19:27:32      <NA>                  <NA>   \n\n  time_observed  forecast_length  month   day  dow  \n0          <NA>               24    7.0  20.0  6.0  \n1          <NA>               24    7.0  20.0  6.0  \n2          <NA>               24    7.0  20.0  6.0  \n3          <NA>               24    7.0  20.0  6.0  \n4          <NA>               24    7.0  20.0  6.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>user_id</th>\n      <th>confidence</th>\n      <th>predicted_intensity</th>\n      <th>community</th>\n      <th>district</th>\n      <th>prediction_time</th>\n      <th>indicator</th>\n      <th>indicator_description</th>\n      <th>time_observed</th>\n      <th>forecast_length</th>\n      <th>month</th>\n      <th>day</th>\n      <th>dow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_SbTdy_24</td>\n      <td>77</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>ASSIN BROFOYEDUR</td>\n      <td>assin_fosu</td>\n      <td>2025-07-20 19:27:28</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>24</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_SBKYz_24</td>\n      <td>77</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>ASSIN BROFOYEDUR</td>\n      <td>assin_fosu</td>\n      <td>2025-07-20 19:27:29</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>24</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_fAimg_24</td>\n      <td>77</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>ASSIN BROFOYEDUR</td>\n      <td>assin_fosu</td>\n      <td>2025-07-20 19:27:30</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>24</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_2wBqC_24</td>\n      <td>77</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>ASSIN BROFOYEDUR</td>\n      <td>assin_fosu</td>\n      <td>2025-07-20 19:27:31</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>24</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_NItox_24</td>\n      <td>77</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>ASSIN BROFOYEDUR</td>\n      <td>assin_fosu</td>\n      <td>2025-07-20 19:27:32</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>24</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>6.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"CATS = [\"community\",\"district\",\"indicator\",\"indicator_description\",\"time_observed\"]\nlists2 = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T17:51:36.991400Z","iopub.execute_input":"2025-09-19T17:51:36.991565Z","iopub.status.idle":"2025-09-19T17:51:36.994968Z","shell.execute_reply.started":"2025-09-19T17:51:36.991551Z","shell.execute_reply":"2025-09-19T17:51:36.994204Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"combined = pd.concat([train,test],axis=0,ignore_index=True)\nfor f1, f2 in itertools.combinations(CATS, 2):\n    name = f\"{f1}_{f2}\"\n    # combined[name] = combined[f1].astype(\"str\") + \"_\" + combined[f2].astype(\"str\")\n    lists2.append([f1, f2])\n\nfor f1, f2, f3 in itertools.combinations(CATS, 3):\n    name = f\"{f1}_{f2}_{f3}\"\n    # combined[name] = combined[f1].astype(\"str\") + \"_\" + combined[f2].astype(\"str\") + \"_\" + combined[f3].astype(\"str\")\n    lists2.append([f1, f2, f3])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T17:51:36.995907Z","iopub.execute_input":"2025-09-19T17:51:36.996143Z","iopub.status.idle":"2025-09-19T17:51:37.049170Z","shell.execute_reply.started":"2025-09-19T17:51:36.996120Z","shell.execute_reply":"2025-09-19T17:51:37.048389Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"RMV = [\"ID\", \"prediction_time\", \"Target\"]\nEXPERIMENT_COLS = [c for c in train.columns if c not in RMV]\ntemp = train[EXPERIMENT_COLS].copy()\ntemp = temp.fillna(\"MISSING\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T17:51:37.051455Z","iopub.execute_input":"2025-09-19T17:51:37.051695Z","iopub.status.idle":"2025-09-19T17:51:37.100047Z","shell.execute_reply.started":"2025-09-19T17:51:37.051679Z","shell.execute_reply":"2025-09-19T17:51:37.099348Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from sklearn.feature_selection import SequentialFeatureSelector, mutual_info_classif\nfrom sklearn.model_selection import StratifiedKFold\nfrom cuml.ensemble import RandomForestClassifier\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=44)\nfor i in range(2, 7):\n    for cols in itertools.combinations(EXPERIMENT_COLS, i):\n        name = \"_\".join(cols)\n        temp[name] = temp[list(cols)].astype(\"str\").agg(\"_\".join, axis=1)\n        EXPERIMENT_COLS.append(name)\n        \nfor col in temp.columns:\n    temp[col], _ = temp[col].factorize()\n        \n# Base model\nestimator = RandomForestClassifier()\n\n# Forward Feature Selection\nsfs = SequentialFeatureSelector(\n    estimator,\n    n_features_to_select=\"auto\",   # can be int or \"auto\"\n    direction=\"forward\",      # forward or backward\n    scoring=\"f1_macro\", \n    verbose=100,              # choose metric\n    cv=skf                      # cross-validation folds\n)\n\nsfs.fit(temp, train[\"Target\"])\n\n# Get selected features\nselected_features = temp.columns[sfs.get_support()]\nprint(\"Selected features:\", selected_features.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T17:51:37.100703Z","iopub.execute_input":"2025-09-19T17:51:37.100886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Index(['community_district_indicator_user_id_confidence_forecast_length',\n#        'community_time_observed_user_id_confidence_predicted_intensity_forecast_length',\n#        'community_indicator_indicator_description_user_id_confidence_forecast_length',\n#        'community_district_user_id_confidence_predicted_intensity_forecast_length',\n#        'community_user_id_confidence_predicted_intensity_forecast_length',\n#        'community_indicator_user_id_confidence_forecast_length',\n#        'community_indicator_time_observed_user_id_confidence_forecast_length',\n#        'community_district_indicator_indicator_description_user_id_forecast_length',\n#        'community_user_id_confidence_forecast_length',\n#        'community_indicator_time_observed_user_id_forecast_length'],\n#       dtype='object')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# combined[\"Target\"] = combined[\"Target\"].map({\"NORAIN\": 0, \"SMALLRAIN\": 1, \"MEDIUMRAIN\": 2, \"HEAVYRAIN\": 3})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# RMV = [\"ID\",\"prediction_time\",\"Target\"]\n# FEATURES = [c for c in train.columns if not c in RMV]\n\n\n# HIGH_CARDINALITY = []\n# print(f\"THE {len(FEATURES)} BASIC FEATURES ARE:\")\n# for c in FEATURES:\n#     ftype = \"numerical\"\n#     if combined[c].dtype==\"object\":\n#         if c in [\"community\", \"indicator\", \"indicator_description\"]:\n#             combined[c] = ( combined[c].str.lower().str.replace(r\"\\s+\", \" \", regex=True).str.strip() )\n#         combined[c] = combined[c].fillna(\"NAN\")\n#         combined[c],_ = combined[c].factorize()\n#         combined[c] -= combined[c].min()\n#         ftype = \"categorical\"\n#     if combined[c].dtype==\"int64\":\n#         combined[c] = combined[c].astype(\"int32\")\n#     elif combined[c].dtype==\"float64\":\n#         combined[c] = combined[c].astype(\"float32\")\n        \n#     n = combined[c].nunique()\n#     print(f\"{c} ({ftype}) with {n} unique values\")\n#     if n>=9: HIGH_CARDINALITY.append(c)\n    \n# train = combined.iloc[:len(train)].copy()\n# test = combined.iloc[len(train):].reset_index(drop=True).copy()\n\n# print(\"\\nTHE FOLLOWING HAVE 9 OR MORE UNIQUE VALUES:\", HIGH_CARDINALITY )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def target_encode(train, valid, test, col, target=\"Target\", kfold=5, smooth=20, agg=\"mean\"):\n\n#     train['kfold'] = ((train.index) % kfold)\n#     col_name = '_'.join(col)\n#     train[f'TE_{agg.upper()}_' + col_name] = 0.\n#     for i in range(kfold):\n        \n#         df_tmp = train[train['kfold']!=i]\n#         if agg==\"mean\": mn = train[target].mean()\n#         elif agg==\"median\": mn = train[target].median()\n#         elif agg==\"min\": mn = train[target].min()\n#         elif agg==\"max\": mn = train[target].max()\n#         elif agg==\"nunique\": mn = 0\n#         df_tmp = df_tmp[col + [target]].groupby(col).agg([agg, 'count']).reset_index()\n#         df_tmp.columns = col + [agg, 'count']\n#         if agg==\"nunique\":\n#             df_tmp['TE_tmp'] = df_tmp[agg] / df_tmp['count']\n#         else:\n#             df_tmp['TE_tmp'] = ((df_tmp[agg]*df_tmp['count'])+(mn*smooth)) / (df_tmp['count']+smooth)\n#         df_tmp_m = train[col + ['kfold', f'TE_{agg.upper()}_' + col_name]].merge(df_tmp, how='left', left_on=col, right_on=col)\n#         df_tmp_m.loc[df_tmp_m['kfold']==i, f'TE_{agg.upper()}_' + col_name] = df_tmp_m.loc[df_tmp_m['kfold']==i, 'TE_tmp']\n#         train[f'TE_{agg.upper()}_' + col_name] = df_tmp_m[f'TE_{agg.upper()}_' + col_name].fillna(mn).values  \n    \n#     df_tmp = train[col + [target]].groupby(col).agg([agg, 'count']).reset_index()\n#     if agg==\"mean\": mn = train[target].mean()\n#     elif agg==\"median\": mn = train[target].median()\n#     elif agg==\"min\": mn = train[target].min()\n#     elif agg==\"max\": mn = train[target].max()\n#     elif agg==\"nunique\": mn = 0\n#     df_tmp.columns = col + [agg, 'count']\n#     if agg==\"nunique\":\n#         df_tmp['TE_tmp'] = df_tmp[agg] / df_tmp['count']\n#     else:\n#         df_tmp['TE_tmp'] = ((df_tmp[agg]*df_tmp['count'])+(mn*smooth)) / (df_tmp['count']+smooth)\n#     df_tmp_m = valid[col].merge(df_tmp, how='left', left_on=col, right_on=col)\n#     valid[f'TE_{agg.upper()}_' + col_name] = df_tmp_m['TE_tmp'].fillna(mn).values\n#     valid[f'TE_{agg.upper()}_' + col_name] = valid[f'TE_{agg.upper()}_' + col_name].astype(\"float32\")\n\n#     df_tmp_m = test[col].merge(df_tmp, how='left', left_on=col, right_on=col)\n#     test[f'TE_{agg.upper()}_' + col_name] = df_tmp_m['TE_tmp'].fillna(mn).values\n#     test[f'TE_{agg.upper()}_' + col_name] = test[f'TE_{agg.upper()}_' + col_name].astype(\"float32\")\n\n#     train = train.drop('kfold', axis=1)\n#     train[f'TE_{agg.upper()}_' + col_name] = train[f'TE_{agg.upper()}_' + col_name].astype(\"float32\")\n\n#     return (train, valid, test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from xgboost import XGBClassifier\n# import xgboost as xgb, time\n# print(f\"Using XGBoost version\",xgb.__version__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%time\n\n# FOLDS = 20\n# from sklearn.model_selection import StratifiedKFold\n# skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=44)\n\n# oof = np.zeros((len(train), 4))\n# pred = np.zeros((len(test), 4))\n\n# for i, (train_index, test_index) in enumerate(skf.split(train, train[\"Target\"])):\n\n#     print(\"#\"*25)\n#     print(f\"### Fold {i+1}\")\n#     print(\"#\"*25)\n    \n#     x_train = train.loc[train_index,FEATURES+[\"Target\"] ].copy()\n#     y_train = train.loc[train_index,\"Target\"]\n#     x_valid = train.loc[test_index,FEATURES].copy()\n#     y_valid = train.loc[test_index,\"Target\"]\n#     x_test = test[FEATURES].copy()\n\n#     start = time.time()\n#     print(f\"FEATURE ENGINEER {len(FEATURES)} COLUMNS and {len(lists2)} GROUPS: \",end=\"\")\n#     for j,f in enumerate(FEATURES+lists2):\n\n#         if j<len(FEATURES): c = [f]\n#         else: c = f\n#         print(f\"({j+1}){c}\",\", \",end=\"\")\n\n#         # LOW CARDINALITY FEATURES - TARGET ENCODE MEAN AND MEDIAN\n#         x_train, x_valid, x_test = target_encode(x_train, x_valid, x_test, c, smooth=20, agg=\"mean\")\n#         x_train, x_valid, x_test = target_encode(x_train, x_valid, x_test, c, smooth=0, agg=\"median\")\n\n#         # HIGH CARDINALITY FEATURES - TE MIN, MAX, NUNIQUE and CE\n#         if (j>=len(FEATURES)) | (c[0] in HIGH_CARDINALITY):\n#             x_train, x_valid, x_test = target_encode(x_train, x_valid, x_test, c, smooth=0, agg=\"min\")\n#             x_train, x_valid, x_test = target_encode(x_train, x_valid, x_test, c, smooth=0, agg=\"max\")\n#             x_train, x_valid, x_test = target_encode(x_train, x_valid, x_test, c, smooth=0, agg=\"nunique\")\n    \n#             # COUNT ENCODING (USING COMBINED TRAIN TEST)\n#             tmp = combined.groupby(c).Target.count()\n#             nm = f\"CE_{'_'.join(c)}\"; tmp.name = nm\n#             x_train = x_train.merge(tmp, on=c, how=\"left\")\n#             x_valid = x_valid.merge(tmp, on=c, how=\"left\")\n#             x_test = x_test.merge(tmp, on=c, how=\"left\")\n#             x_train[nm] = x_train[nm].astype(\"int32\")\n#             x_valid[nm] = x_valid[nm].astype(\"int32\")\n#             x_test[nm] = x_test[nm].astype(\"int32\")\n            \n#     end = time.time()\n#     elapsed = end-start\n#     print(f\"Feature engineering took {elapsed:.1f} seconds\")\n#     x_train = x_train.drop(\"Target\",axis=1)\n\n#     model = XGBClassifier(\n#         device=\"cuda\",\n#         max_depth=8, \n#         colsample_bytree=0.9, \n#         subsample=0.9, \n#         n_estimators=2_000, \n#         learning_rate=0.01, \n#         num_class=4,\n#         early_stopping_rounds=25,  \n#         objective=\"multi:softprob\",\n#         eval_metric=\"mlogloss\",\n#     )\n#     model.fit(\n#         x_train, y_train,\n#         eval_set=[(x_valid, y_valid)],   \n#         verbose=100\n#     )\n\n#     # INFER OOF\n#     oof[test_index] = model.predict_proba(x_valid)\n#     # INFER TEST\n#     pred += model.predict_proba(x_test)\n\n#     # m = np.sqrt(np.mean( (y_valid.to_numpy() - oof[test_index])**2.0 )) \n#     # print(f\" => Fold {i+1} RMSLE = {m:.5f}\")\n\n# # COMPUTE AVERAGE TEST PREDS\n# pred /= FOLDS","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# preds = np.argmax(pred, axis=1)\n# data = {\"ID\": test.ID, \"Target\": preds}\n# submission = pd.DataFrame(data)\n# submission[\"Target\"] = submission[\"Target\"].map({0: \"NORAIN\", 1: \"SMALLRAIN\", 2: \"MEDIUMRAIN\", 3: \"HEAVYRAIN\"})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from sklearn.metrics import f1_score\n# oof_pred = np.argmax(oof, axis=1)\n# print(f1_score(train[\"Target\"], oof_pred, average=\"macro\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# submission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}