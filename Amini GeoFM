{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12272963,"sourceType":"datasetVersion","datasetId":7734161},{"sourceId":12273448,"sourceType":"datasetVersion","datasetId":7734425}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import all the necessary libraries","metadata":{"id":"HrDEr5o8ypNR"}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom transformers import PatchTSTForPretraining\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, accuracy_score, classification_report\nimport pandas as pd\nimport numpy as np\nfrom scipy.interpolate import CubicSpline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport os\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"id":"AOiUiHLkypNT","outputId":"5933711e-86a0-4280-f983-97a9ef42b867","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:35:06.466234Z","iopub.execute_input":"2025-07-01T21:35:06.466505Z","iopub.status.idle":"2025-07-01T21:35:47.902150Z","shell.execute_reply.started":"2025-07-01T21:35:06.466487Z","shell.execute_reply":"2025-07-01T21:35:47.901415Z"}},"outputs":[{"name":"stderr","text":"2025-07-01 21:35:30.166209: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751405730.607249      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751405730.731694      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Data preprocessing\n - The earth FM expects 48 timesteps per pixel. Make sure to aggregate appropriately\n","metadata":{"id":"TREGjqdXypNW"}},{"cell_type":"code","source":"# This is a dummy dataset\n# N.B. This df is for illustration only and should only be used to get an understanding of the problem. This data is completely fictious.\ntrain_data = pd.read_csv('/kaggle/input/dummy-satellite-dataset/dummy_satellite_data.csv')\ntrain_data.head()\n","metadata":{"id":"9nnS_pOZypNW","outputId":"66f99869-99ae-44e2-a384-dc7d3632294b","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:35:47.902975Z","iopub.execute_input":"2025-07-01T21:35:47.903603Z","iopub.status.idle":"2025-07-01T21:35:48.077836Z","shell.execute_reply.started":"2025-07-01T21:35:47.903568Z","shell.execute_reply":"2025-07-01T21:35:48.077061Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"    unique_id                     time              x              y  \\\n0  PIXEL_0001  2018-01-01 00:00:00.000  274312.192156  763161.256666   \n1  PIXEL_0001  2018-01-09 00:00:00.000  274312.192156  763161.256666   \n2  PIXEL_0001  2018-01-17 00:00:00.000  274312.192156  763161.256666   \n3  PIXEL_0001  2018-01-25 00:00:00.000  274312.192156  763161.256666   \n4  PIXEL_0001  2018-02-02 00:00:00.000  274312.192156  763161.256666   \n\n  crop_type       red       nir    swir16    swir22      blue     green  \\\n0     cocoa  0.185399  0.470621  0.423230  0.248294  0.240145  0.220656   \n1     cocoa  0.220038  0.532922  0.309975  0.323104  0.266787  0.294504   \n2     cocoa  0.250492  0.630413  0.290035  0.331941  0.338385  0.348162   \n3     cocoa  0.259566  0.487199  0.381297  0.322500  0.292686  0.420341   \n4     cocoa  0.300939  0.670061  0.448583  0.364932  0.350569  0.289149   \n\n   rededge1  rededge2  rededge3     nir08  \n0  0.322180  0.482940  0.449330  0.477607  \n1  0.525136  0.502824  0.423608  0.422886  \n2  0.350808  0.461883  0.514735  0.578810  \n3  0.401141  0.504158  0.480010  0.569881  \n4  0.406982  0.506831  0.534893  0.541207  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_id</th>\n      <th>time</th>\n      <th>x</th>\n      <th>y</th>\n      <th>crop_type</th>\n      <th>red</th>\n      <th>nir</th>\n      <th>swir16</th>\n      <th>swir22</th>\n      <th>blue</th>\n      <th>green</th>\n      <th>rededge1</th>\n      <th>rededge2</th>\n      <th>rededge3</th>\n      <th>nir08</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PIXEL_0001</td>\n      <td>2018-01-01 00:00:00.000</td>\n      <td>274312.192156</td>\n      <td>763161.256666</td>\n      <td>cocoa</td>\n      <td>0.185399</td>\n      <td>0.470621</td>\n      <td>0.423230</td>\n      <td>0.248294</td>\n      <td>0.240145</td>\n      <td>0.220656</td>\n      <td>0.322180</td>\n      <td>0.482940</td>\n      <td>0.449330</td>\n      <td>0.477607</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PIXEL_0001</td>\n      <td>2018-01-09 00:00:00.000</td>\n      <td>274312.192156</td>\n      <td>763161.256666</td>\n      <td>cocoa</td>\n      <td>0.220038</td>\n      <td>0.532922</td>\n      <td>0.309975</td>\n      <td>0.323104</td>\n      <td>0.266787</td>\n      <td>0.294504</td>\n      <td>0.525136</td>\n      <td>0.502824</td>\n      <td>0.423608</td>\n      <td>0.422886</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PIXEL_0001</td>\n      <td>2018-01-17 00:00:00.000</td>\n      <td>274312.192156</td>\n      <td>763161.256666</td>\n      <td>cocoa</td>\n      <td>0.250492</td>\n      <td>0.630413</td>\n      <td>0.290035</td>\n      <td>0.331941</td>\n      <td>0.338385</td>\n      <td>0.348162</td>\n      <td>0.350808</td>\n      <td>0.461883</td>\n      <td>0.514735</td>\n      <td>0.578810</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>PIXEL_0001</td>\n      <td>2018-01-25 00:00:00.000</td>\n      <td>274312.192156</td>\n      <td>763161.256666</td>\n      <td>cocoa</td>\n      <td>0.259566</td>\n      <td>0.487199</td>\n      <td>0.381297</td>\n      <td>0.322500</td>\n      <td>0.292686</td>\n      <td>0.420341</td>\n      <td>0.401141</td>\n      <td>0.504158</td>\n      <td>0.480010</td>\n      <td>0.569881</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PIXEL_0001</td>\n      <td>2018-02-02 00:00:00.000</td>\n      <td>274312.192156</td>\n      <td>763161.256666</td>\n      <td>cocoa</td>\n      <td>0.300939</td>\n      <td>0.670061</td>\n      <td>0.448583</td>\n      <td>0.364932</td>\n      <td>0.350569</td>\n      <td>0.289149</td>\n      <td>0.406982</td>\n      <td>0.506831</td>\n      <td>0.534893</td>\n      <td>0.541207</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/test-data/test (1).csv')\ntest_data.head()","metadata":{"id":"V4bCSsQnypNX","outputId":"594604d8-e26f-4ce2-85ac-6f91d95e787d","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:35:48.079764Z","iopub.execute_input":"2025-07-01T21:35:48.079991Z","iopub.status.idle":"2025-07-01T21:35:52.098904Z","shell.execute_reply.started":"2025-07-01T21:35:48.079974Z","shell.execute_reply":"2025-07-01T21:35:52.097983Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   unique_id                     time         x         y     red     nir  \\\n0  ID_01FHV4  2018-01-03 10:59:22.851 -296455.0  846395.0  0.2920  0.3686   \n1  ID_01FHV4  2018-01-03 10:59:22.851 -296455.0  846395.0  0.2920  0.3686   \n2  ID_01FHV4  2018-02-12 10:59:25.232 -296455.0  846395.0  0.3510  0.3426   \n3  ID_01FHV4  2018-02-12 10:59:25.232 -296455.0  846395.0  0.3510  0.3426   \n4  ID_01FHV4  2018-03-14 10:59:24.436 -296455.0  846395.0  0.5312  0.6296   \n\n   swir16  swir22    blue   green  rededge1  rededge2  rededge3   nir08  \n0  0.4173  0.3869  0.2488  0.2708    0.3211    0.3555    0.3752  0.3862  \n1  0.4173  0.3869  0.2488  0.2708    0.3211    0.3555    0.3752  0.3862  \n2  0.4817  0.4577  0.2538  0.2914    0.3684    0.3484    0.3588  0.3628  \n3  0.4817  0.4577  0.2538  0.2914    0.3684    0.3484    0.3588  0.3628  \n4  0.6643  0.5882  0.5244  0.5308    0.6016    0.6217    0.6401  0.6404  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_id</th>\n      <th>time</th>\n      <th>x</th>\n      <th>y</th>\n      <th>red</th>\n      <th>nir</th>\n      <th>swir16</th>\n      <th>swir22</th>\n      <th>blue</th>\n      <th>green</th>\n      <th>rededge1</th>\n      <th>rededge2</th>\n      <th>rededge3</th>\n      <th>nir08</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_01FHV4</td>\n      <td>2018-01-03 10:59:22.851</td>\n      <td>-296455.0</td>\n      <td>846395.0</td>\n      <td>0.2920</td>\n      <td>0.3686</td>\n      <td>0.4173</td>\n      <td>0.3869</td>\n      <td>0.2488</td>\n      <td>0.2708</td>\n      <td>0.3211</td>\n      <td>0.3555</td>\n      <td>0.3752</td>\n      <td>0.3862</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_01FHV4</td>\n      <td>2018-01-03 10:59:22.851</td>\n      <td>-296455.0</td>\n      <td>846395.0</td>\n      <td>0.2920</td>\n      <td>0.3686</td>\n      <td>0.4173</td>\n      <td>0.3869</td>\n      <td>0.2488</td>\n      <td>0.2708</td>\n      <td>0.3211</td>\n      <td>0.3555</td>\n      <td>0.3752</td>\n      <td>0.3862</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_01FHV4</td>\n      <td>2018-02-12 10:59:25.232</td>\n      <td>-296455.0</td>\n      <td>846395.0</td>\n      <td>0.3510</td>\n      <td>0.3426</td>\n      <td>0.4817</td>\n      <td>0.4577</td>\n      <td>0.2538</td>\n      <td>0.2914</td>\n      <td>0.3684</td>\n      <td>0.3484</td>\n      <td>0.3588</td>\n      <td>0.3628</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_01FHV4</td>\n      <td>2018-02-12 10:59:25.232</td>\n      <td>-296455.0</td>\n      <td>846395.0</td>\n      <td>0.3510</td>\n      <td>0.3426</td>\n      <td>0.4817</td>\n      <td>0.4577</td>\n      <td>0.2538</td>\n      <td>0.2914</td>\n      <td>0.3684</td>\n      <td>0.3484</td>\n      <td>0.3588</td>\n      <td>0.3628</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_01FHV4</td>\n      <td>2018-03-14 10:59:24.436</td>\n      <td>-296455.0</td>\n      <td>846395.0</td>\n      <td>0.5312</td>\n      <td>0.6296</td>\n      <td>0.6643</td>\n      <td>0.5882</td>\n      <td>0.5244</td>\n      <td>0.5308</td>\n      <td>0.6016</td>\n      <td>0.6217</td>\n      <td>0.6401</td>\n      <td>0.6404</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"train_data['crop_type'].value_counts()","metadata":{"id":"Cq7fi0rWypNX","outputId":"16ea2d78-f5f3-4fc6-b941-13005402cd00","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:35:52.102227Z","iopub.execute_input":"2025-07-01T21:35:52.102462Z","iopub.status.idle":"2025-07-01T21:35:52.116013Z","shell.execute_reply.started":"2025-07-01T21:35:52.102443Z","shell.execute_reply":"2025-07-01T21:35:52.115208Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"crop_type\ncocoa     4647\nrubber    4645\noil       4642\nName: count, dtype: int64"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"timesteps_per_pixel = train_data.groupby('unique_id').size()  #count the timesteps per pixel since model expects 48 timesteps per pixel\n\nprint(\"Total timesteps per pixel:\", len(timesteps_per_pixel))\nprint(\"Minimum timesteps per pixel:\", timesteps_per_pixel.min())\nprint(\"Maximum timesteps per pixel:\", timesteps_per_pixel.max())\nprint(\"Average timesteps per pixel:\", timesteps_per_pixel.mean())","metadata":{"id":"xWLQg5ibypNY","outputId":"1894978e-90c3-475d-e6ef-338372985074","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:35:52.117102Z","iopub.execute_input":"2025-07-01T21:35:52.117400Z","iopub.status.idle":"2025-07-01T21:35:52.158149Z","shell.execute_reply.started":"2025-07-01T21:35:52.117372Z","shell.execute_reply":"2025-07-01T21:35:52.157180Z"}},"outputs":[{"name":"stdout","text":"Total timesteps per pixel: 300\nMinimum timesteps per pixel: 30\nMaximum timesteps per pixel: 48\nAverage timesteps per pixel: 46.446666666666665\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"test_pixel = test_data.groupby('unique_id').size()  #count the timesteps per pixel since model expects 48 timesteps per pixel\n\nprint(\"Total timesteps per pixel:\", len(test_pixel))\nprint(\"Minimum timesteps per pixel:\", test_pixel.min())\nprint(\"Maximum timesteps per pixel:\", test_pixel.max())\nprint(\"Average timesteps per pixel:\", test_pixel.mean())","metadata":{"id":"lPQl8JTaypNZ","outputId":"5ef9d399-9fda-4067-f6c9-d546f9719637","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:35:52.158947Z","iopub.execute_input":"2025-07-01T21:35:52.159207Z","iopub.status.idle":"2025-07-01T21:35:52.287595Z","shell.execute_reply.started":"2025-07-01T21:35:52.159189Z","shell.execute_reply":"2025-07-01T21:35:52.286792Z"}},"outputs":[{"name":"stdout","text":"Total timesteps per pixel: 10523\nMinimum timesteps per pixel: 74\nMaximum timesteps per pixel: 740\nAverage timesteps per pixel: 114.33155944122399\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"bands = ['red', 'nir', 'swir16', 'swir22', 'blue', 'green','rededge1', 'rededge2', 'rededge3', 'nir08']  # The spectral bands in the dataset","metadata":{"id":"h8euYClRypNZ","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:35:52.288564Z","iopub.execute_input":"2025-07-01T21:35:52.288914Z","iopub.status.idle":"2025-07-01T21:35:52.293500Z","shell.execute_reply.started":"2025-07-01T21:35:52.288886Z","shell.execute_reply":"2025-07-01T21:35:52.292561Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# You can have different ways to aggregate data to the required timesteps\n# Below we have use interpolation, but remember it might introduce noise\n\nfrom scipy.interpolate import CubicSpline\nimport numpy as np\nimport pandas as pd\n\ndef preprocess_with_interpolation(df, bands):\n    all_results = []\n    has_crop_type = 'crop_type' in df.columns\n\n    for pixel_id, group in df.groupby('unique_id'):\n        group = group.sort_values('time').reset_index(drop=True)\n\n        if len(group) == 48:\n            keep_cols = ['unique_id', 'x', 'y'] + bands\n            if has_crop_type:\n                keep_cols.insert(1, 'crop_type')\n\n            clean_group = group[keep_cols].copy()\n            clean_group['timestep'] = range(48)\n            all_results.append(clean_group)\n        else:\n            new_rows = []\n            interpolated_bands = {}\n            old_times = np.arange(len(group))\n            new_times = np.linspace(0, len(group) - 1, 48)\n\n            for band in bands:\n                spline = CubicSpline(old_times, group[band].values)\n                interpolated_bands[band] = spline(new_times)\n\n            for i in range(48):\n                new_row = {\n                    'unique_id': pixel_id,\n                    'timestep': i,\n                    'x': group['x'].iloc[0],\n                    'y': group['y'].iloc[0]\n                }\n                if has_crop_type:\n                    new_row['crop_type'] = group['crop_type'].iloc[0]\n\n                for band in bands:\n                    new_row[band] = interpolated_bands[band][i]\n\n                new_rows.append(new_row)\n\n            all_results.append(pd.DataFrame(new_rows))\n\n    final_df = pd.concat(all_results, ignore_index=True)\n    return final_df\n","metadata":{"id":"50XaeYi_ypNa","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:35:52.297774Z","iopub.execute_input":"2025-07-01T21:35:52.298054Z","iopub.status.idle":"2025-07-01T21:35:52.316123Z","shell.execute_reply.started":"2025-07-01T21:35:52.298027Z","shell.execute_reply":"2025-07-01T21:35:52.315632Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"preprocessed_train_data = preprocess_with_interpolation(train_data, bands)\npreprocessed_test_data = preprocess_with_interpolation(test_data, bands)","metadata":{"id":"i6FZuK4yypNa","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:35:52.316720Z","iopub.execute_input":"2025-07-01T21:35:52.316954Z","iopub.status.idle":"2025-07-01T21:36:37.202222Z","shell.execute_reply.started":"2025-07-01T21:35:52.316934Z","shell.execute_reply":"2025-07-01T21:36:37.201348Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_pixel = preprocessed_train_data.groupby('unique_id').size()  #count the timesteps per pixel since model expects 48 timesteps per pixel\n\nprint(\"Minimum timesteps per pixel:\", train_pixel.min())\nprint(\"Maximum timesteps per pixel:\", train_pixel.max())\n","metadata":{"id":"cdzK5LdUypNb","outputId":"a995de28-1fa6-42b0-ea87-a75212b03453","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:36:37.203210Z","iopub.execute_input":"2025-07-01T21:36:37.203403Z","iopub.status.idle":"2025-07-01T21:36:37.210273Z","shell.execute_reply.started":"2025-07-01T21:36:37.203388Z","shell.execute_reply":"2025-07-01T21:36:37.209517Z"}},"outputs":[{"name":"stdout","text":"Minimum timesteps per pixel: 48\nMaximum timesteps per pixel: 48\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# MODELLING\n- The earth FM was pretrained on a vast amount of Sentinel 2 unlabeled timeseries data, built on [PATCHTST](https://huggingface.co/docs/transformers/en/model_doc/patchtst#transformers.PatchTSTForPretraining) architecture.\n- The pretrained model can be used in different ways: finetuning though supervised classification, as a feature extractor etc.\n\nDownload the models on hugging face\n - [600K](https://huggingface.co/AminiTech/FM-600K)\n - [18M](https://huggingface.co/AminiTech/fm-v2-28M)\n\nThe model expects a dataset and its mask as input","metadata":{"id":"N-6I-F3xypNb"}},{"cell_type":"code","source":"# use the model as a feature extractor for RF model\ndef extract_patch_embeddings(model, past_values):\n    past_observed_mask = ~torch.isnan(past_values)\n\n    with torch.no_grad():\n        model_output = model.model(\n            past_values=past_values,\n            past_observed_mask=past_observed_mask,\n            return_dict=True\n        )\n        embeddings = model_output.last_hidden_state\n        all_patches = embeddings[:, :, 1:, :]\n        final_embeddings = all_patches.mean(dim=(1, 2))  # average of all patch level embeddings\n        return final_embeddings\n","metadata":{"id":"1FW8cp5jypNb","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:36:37.211040Z","iopub.execute_input":"2025-07-01T21:36:37.211267Z","iopub.status.idle":"2025-07-01T21:36:37.242330Z","shell.execute_reply.started":"2025-07-01T21:36:37.211250Z","shell.execute_reply":"2025-07-01T21:36:37.241766Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"hf_token = os.getenv('HUGGINGFACE_HUB_TOKEN')\nMODEL_PATH = \"AminiTech/fm-v2-28M\"\n","metadata":{"id":"lRKlBL0XypNc","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:36:37.243085Z","iopub.execute_input":"2025-07-01T21:36:37.243298Z","iopub.status.idle":"2025-07-01T21:36:37.259489Z","shell.execute_reply.started":"2025-07-01T21:36:37.243282Z","shell.execute_reply":"2025-07-01T21:36:37.258930Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class CropDataset(Dataset):\n    def __init__(self, sequences, labels, unique_ids):\n        self.sequences = torch.FloatTensor(sequences)\n        self.labels = labels\n        self.unique_ids = unique_ids\n\n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, idx):\n        item = {\n            'sequence': self.sequences[idx],\n            'unique_id': self.unique_ids[idx]\n        }\n        if self.labels is not None:\n            item['label'] = self.labels[idx]\n        return item\n\n\ndef prepare_sequences_from_df(df):\n    sequences = []\n    labels = []\n    unique_ids = []\n    has_labels = 'crop_type' in df.columns\n\n    for unique_id, group in df.groupby('unique_id'):\n        spectral_data = group[bands].values\n        sequences.append(spectral_data)\n        unique_ids.append(unique_id)\n\n        if has_labels:\n            labels.append(group['crop_type'].iloc[0])\n\n    sequences = np.array(sequences)\n\n    print(f\"Prepared {len(sequences)} sequences\")\n\n    if has_labels:\n        print(f\"Crop distribution:\")\n        unique, counts = np.unique(labels, return_counts=True)\n        for crop, count in zip(unique, counts):\n            print(f\"  {crop}: {count}\")\n    else:\n        labels = None\n\n    return sequences, labels, unique_ids\n\ndef extract_embeddings_from_dataloader(model, dataloader):\n    model.eval()\n    all_embeddings = []\n    all_ids = []\n\n    device = next(model.parameters()).device\n\n    with torch.no_grad():\n        for batch in dataloader:\n            sequences = batch['sequence'].to(device)\n            embeddings = extract_patch_embeddings(model, sequences)\n\n            all_embeddings.append(embeddings.cpu())  # Move to CPU before collecting\n            all_ids.extend(batch['unique_id'])\n\n    return torch.cat(all_embeddings, dim=0), all_ids","metadata":{"id":"FfN_AFsoypNc","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:36:37.260325Z","iopub.execute_input":"2025-07-01T21:36:37.260569Z","iopub.status.idle":"2025-07-01T21:36:37.278737Z","shell.execute_reply.started":"2025-07-01T21:36:37.260545Z","shell.execute_reply":"2025-07-01T21:36:37.278108Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_seq, train_labels, train_ids = prepare_sequences_from_df(preprocessed_train_data)\ntrain_dataset = CropDataset(train_seq, train_labels, train_ids)\n","metadata":{"id":"oBaXtrRUypNc","outputId":"c0b6cdc3-1878-4071-b0b6-4aaaaa574634","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:36:37.279483Z","iopub.execute_input":"2025-07-01T21:36:37.279863Z","iopub.status.idle":"2025-07-01T21:36:37.423177Z","shell.execute_reply.started":"2025-07-01T21:36:37.279832Z","shell.execute_reply":"2025-07-01T21:36:37.422489Z"}},"outputs":[{"name":"stdout","text":"Prepared 300 sequences\nCrop distribution:\n  cocoa: 100\n  oil: 100\n  rubber: 100\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"print(\"Train sequences shape:\", train_seq.shape)","metadata":{"id":"rcRH8m3-ypNc","outputId":"ef923441-6259-442b-986a-b8d308d16d98","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:36:37.423916Z","iopub.execute_input":"2025-07-01T21:36:37.424165Z","iopub.status.idle":"2025-07-01T21:36:37.428578Z","shell.execute_reply.started":"2025-07-01T21:36:37.424147Z","shell.execute_reply":"2025-07-01T21:36:37.427600Z"}},"outputs":[{"name":"stdout","text":"Train sequences shape: (300, 48, 10)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"test_seq, test_labels, test_ids = prepare_sequences_from_df(preprocessed_test_data)\ntest_dataset = CropDataset(test_seq, test_labels, test_ids)","metadata":{"id":"V7gO8sbFypNc","outputId":"ddcd6436-1522-48d2-e102-07fab00f279c","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:36:37.429428Z","iopub.execute_input":"2025-07-01T21:36:37.429696Z","iopub.status.idle":"2025-07-01T21:36:40.831447Z","shell.execute_reply.started":"2025-07-01T21:36:37.429678Z","shell.execute_reply":"2025-07-01T21:36:40.830796Z"}},"outputs":[{"name":"stdout","text":"Prepared 10523 sequences\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(\"Test sequences shape:\", test_seq.shape)","metadata":{"id":"1BOBTmARypNd","outputId":"510dfdae-4342-47a3-e1b7-228a17898749","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:36:40.832222Z","iopub.execute_input":"2025-07-01T21:36:40.832442Z","iopub.status.idle":"2025-07-01T21:36:40.836838Z","shell.execute_reply.started":"2025-07-01T21:36:40.832425Z","shell.execute_reply":"2025-07-01T21:36:40.836075Z"}},"outputs":[{"name":"stdout","text":"Test sequences shape: (10523, 48, 10)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)","metadata":{"id":"FRCoflX2ypNd","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:36:40.837458Z","iopub.execute_input":"2025-07-01T21:36:40.837683Z","iopub.status.idle":"2025-07-01T21:36:40.852873Z","shell.execute_reply.started":"2025-07-01T21:36:40.837666Z","shell.execute_reply":"2025-07-01T21:36:40.852311Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Load model\nmodel = PatchTSTForPretraining.from_pretrained(MODEL_PATH, token=hf_token)\nmodel.eval()","metadata":{"id":"sIri9nXJypNd","outputId":"55c7418a-4f69-428f-a1e2-8919c4ed67e8","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:36:40.853597Z","iopub.execute_input":"2025-07-01T21:36:40.854078Z","iopub.status.idle":"2025-07-01T21:36:42.208538Z","shell.execute_reply.started":"2025-07-01T21:36:40.854060Z","shell.execute_reply":"2025-07-01T21:36:42.207766Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"202200690e4a4bd8bd05b2fe4be94067"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/75.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba4c7404e4244cfabc1533b4fff6e33f"}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"PatchTSTForPretraining(\n  (model): PatchTSTModel(\n    (scaler): PatchTSTScaler(\n      (scaler): PatchTSTMeanScaler()\n    )\n    (patchifier): PatchTSTPatchify()\n    (masking): PatchTSTMasking()\n    (encoder): PatchTSTEncoder(\n      (embedder): PatchTSTEmbedding(\n        (input_embedding): Linear(in_features=12, out_features=512, bias=True)\n      )\n      (positional_encoder): PatchTSTPositionalEncoding(\n        (positional_dropout): Identity()\n      )\n      (layers): ModuleList(\n        (0-5): 6 x PatchTSTEncoderLayer(\n          (self_attn): PatchTSTAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (dropout_path1): Identity()\n          (norm_sublayer1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (dropout_path2): Identity()\n          (norm_sublayer2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (ff): Sequential(\n            (0): Linear(in_features=512, out_features=2048, bias=True)\n            (1): GELUActivation()\n            (2): Identity()\n            (3): Linear(in_features=2048, out_features=512, bias=True)\n          )\n          (dropout_path3): Identity()\n          (norm_sublayer3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (head): PatchTSTMaskPretrainHead(\n    (dropout): Dropout(p=0.1, inplace=False)\n    (linear): Linear(in_features=512, out_features=12, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"train_embeddings, train_ids = extract_embeddings_from_dataloader(model, train_loader)\ntest_embeddings, test_ids = extract_embeddings_from_dataloader(model, test_loader)\n","metadata":{"id":"3JCxCw5jypNd","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:36:42.209624Z","iopub.execute_input":"2025-07-01T21:36:42.210185Z","iopub.status.idle":"2025-07-01T21:39:26.052399Z","shell.execute_reply.started":"2025-07-01T21:36:42.210158Z","shell.execute_reply":"2025-07-01T21:39:26.051554Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"print(f\"Embeddings shape: Train {train_embeddings.shape}, Test {test_embeddings.shape}\")","metadata":{"id":"DaY3K2oEypNe","outputId":"2f0fa36f-18d9-4e18-c01c-ce787511be28","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:39:26.053478Z","iopub.execute_input":"2025-07-01T21:39:26.053900Z","iopub.status.idle":"2025-07-01T21:39:26.058106Z","shell.execute_reply.started":"2025-07-01T21:39:26.053875Z","shell.execute_reply":"2025-07-01T21:39:26.057402Z"}},"outputs":[{"name":"stdout","text":"Embeddings shape: Train torch.Size([300, 512]), Test torch.Size([10523, 512])\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ntrain_labels_encoded = label_encoder.fit_transform(train_labels)\n","metadata":{"id":"QGERFIy-ypNe","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:39:26.058951Z","iopub.execute_input":"2025-07-01T21:39:26.059260Z","iopub.status.idle":"2025-07-01T21:39:26.076423Z","shell.execute_reply.started":"2025-07-01T21:39:26.059244Z","shell.execute_reply":"2025-07-01T21:39:26.075950Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"rf_model = RandomForestClassifier(class_weight=\"balanced\", random_state=42, n_estimators=100)\nrf_model.fit(train_embeddings.numpy(), train_labels_encoded)","metadata":{"id":"CY_2M-CaypNe","outputId":"74d80dc8-3d8a-40c4-a573-b2564e662000","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T21:39:26.077070Z","iopub.execute_input":"2025-07-01T21:39:26.077232Z","iopub.status.idle":"2025-07-01T21:39:26.504543Z","shell.execute_reply.started":"2025-07-01T21:39:26.077219Z","shell.execute_reply":"2025-07-01T21:39:26.503830Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(class_weight='balanced', random_state=42)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# Evaluate\ntest_predictions_encoded = rf_model.predict_proba(test_embeddings.numpy())\n","metadata":{"id":"TF16XrFlypNe","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T22:18:27.869397Z","iopub.execute_input":"2025-07-01T22:18:27.869866Z","iopub.status.idle":"2025-07-01T22:18:27.994268Z","shell.execute_reply.started":"2025-07-01T22:18:27.869839Z","shell.execute_reply":"2025-07-01T22:18:27.993517Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"submission = pd.DataFrame(test_predictions_encoded, columns=label_encoder.inverse_transform(rf_model.classes_))\nsubmission.insert(0, 'unique_id', test_ids)\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"id":"-CVk3DYOypNe","outputId":"d608169e-070a-4a7d-a5a8-c8860d790248","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T22:21:46.840175Z","iopub.execute_input":"2025-07-01T22:21:46.840450Z","iopub.status.idle":"2025-07-01T22:21:46.875561Z","shell.execute_reply.started":"2025-07-01T22:21:46.840430Z","shell.execute_reply":"2025-07-01T22:21:46.874949Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}